"""Fonctions de nettoyage des donn√©es pour la couche Silver"""

import pandas as pd
import numpy as np
from typing import Optional, List, Dict
from datetime import datetime


def handle_missing_values(
    df: pd.DataFrame,
    strategy: str = "drop",
    columns: Optional[List[str]] = None,
    fill_value: Optional[any] = None
) -> pd.DataFrame:
    """
    G√®re les valeurs manquantes selon une strat√©gie.
    
    Args:
        df: DataFrame √† nettoyer
        strategy: "drop" (supprimer), "fill" (remplacer), "forward_fill"
        columns: Colonnes sp√©cifiques √† traiter (None = toutes)
        fill_value: Valeur de remplacement si strategy="fill"
    
    Returns:
        DataFrame nettoy√©
    """
    df_clean = df.copy()
    
    if columns is None:
        columns = df_clean.columns.tolist()
    
    if strategy == "drop":
        df_clean = df_clean.dropna(subset=columns)
    elif strategy == "fill":
        if fill_value is not None:
            df_clean[columns] = df_clean[columns].fillna(fill_value)
        else:
            # Remplissage par la moyenne pour num√©riques, mode pour cat√©gorielles
            for col in columns:
                if df_clean[col].dtype in ['int64', 'float64']:
                    df_clean[col].fillna(df_clean[col].mean(), inplace=True)
                else:
                    df_clean[col].fillna(df_clean[col].mode()[0] if len(df_clean[col].mode()) > 0 else "UNKNOWN", inplace=True)
    elif strategy == "forward_fill":
        df_clean[columns] = df_clean[columns].ffill()
    
    return df_clean


def standardize_dates(
    df: pd.DataFrame,
    date_columns: List[str],
    target_format: str = "%Y-%m-%d"
) -> pd.DataFrame:
    """
    Standardise les formats de dates.
    
    Args:
        df: DataFrame contenant les colonnes de dates
        date_columns: Liste des colonnes de dates √† standardiser
        target_format: Format cible (pour affichage)
    
    Returns:
        DataFrame avec dates standardis√©es
    """
    df_clean = df.copy()
    
    for col in date_columns:
        if col in df_clean.columns:
            # Convertir en datetime
            df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', infer_datetime_format=True)
            
            # Supprimer les dates futures (anomalies)
            today = pd.Timestamp.now()
            df_clean = df_clean[df_clean[col] <= today]
    
    return df_clean


def normalize_data_types(
    df: pd.DataFrame,
    schema: Dict[str, str]
) -> pd.DataFrame:
    """
    Normalise les types de donn√©es selon un sch√©ma.
    
    Args:
        df: DataFrame √† normaliser
        schema: Dict {colonne: type} ex: {"id": "int64", "montant": "float64"}
    
    Returns:
        DataFrame avec types normalis√©s
    """
    df_clean = df.copy()
    
    for col, dtype in schema.items():
        if col in df_clean.columns:
            try:
                if dtype == "string":
                    df_clean[col] = df_clean[col].astype("string")
                elif dtype == "datetime64[ns]":
                    df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')
                else:
                    df_clean[col] = df_clean[col].astype(dtype)
            except Exception as e:
                print(f"Warning: Impossible de convertir {col} en {dtype}: {e}")
    
    return df_clean


def remove_duplicates(
    df: pd.DataFrame,
    subset: Optional[List[str]] = None,
    keep: str = "first"
) -> pd.DataFrame:
    """
    Supprime les doublons.
    
    Args:
        df: DataFrame √† d√©dupliquer
        subset: Colonnes √† consid√©rer pour la d√©tection (None = toutes)
        keep: "first" (garder premier), "last" (garder dernier), False (supprimer tous)
    
    Returns:
        DataFrame d√©dupliqu√©
    """
    df_clean = df.copy()
    
    initial_count = len(df_clean)
    df_clean = df_clean.drop_duplicates(subset=subset, keep=keep)
    removed_count = initial_count - len(df_clean)
    
    if removed_count > 0:
        print(f"‚ö†Ô∏è  {removed_count} doublon(s) supprim√©(s)")
    
    return df_clean


def clean_clients_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Nettoie sp√©cifiquement les donn√©es clients.
    
    Args:
        df: DataFrame clients brut
    
    Returns:
        DataFrame clients nettoy√©
    """
    print(f"üìä Nettoyage clients: {len(df)} enregistrements initiaux")
    
    # 1. Normaliser les types
    schema = {
        "id_client": "int64",
        "nom": "string",
        "email": "string",
        "date_inscription": "datetime64[ns]",
        "pays": "string"
    }
    df_clean = normalize_data_types(df, schema)
    
    # 2. Supprimer les doublons sur id_client (cl√© primaire)
    df_clean = remove_duplicates(df_clean, subset=["id_client"], keep="first")
    
    # 3. Supprimer les doublons sur email (doit √™tre unique)
    df_clean = remove_duplicates(df_clean, subset=["email"], keep="first")
    
    # 4. Standardiser les dates
    df_clean = standardize_dates(df_clean, date_columns=["date_inscription"])
    
    # 5. G√©rer les valeurs nulles
    # Supprimer les lignes avec nom ou email manquant (critique)
    df_clean = handle_missing_values(
        df_clean,
        strategy="drop",
        columns=["nom", "email"]
    )
    
    # Remplacer les pays manquants par "UNKNOWN"
    df_clean = handle_missing_values(
        df_clean,
        strategy="fill",
        columns=["pays"],
        fill_value="UNKNOWN"
    )
    
    # 6. Validation email basique
    df_clean = df_clean[df_clean["email"].str.contains("@", na=False)]
    
    print(f"‚úÖ Nettoyage clients termin√©: {len(df_clean)} enregistrements valides")
    
    return df_clean


def clean_achats_data(df: pd.DataFrame, valid_client_ids: Optional[pd.Series] = None) -> pd.DataFrame:
    """
    Nettoie sp√©cifiquement les donn√©es achats.
    
    Args:
        df: DataFrame achats brut
        valid_client_ids: Series des id_client valides (pour int√©grit√© r√©f√©rentielle)
    
    Returns:
        DataFrame achats nettoy√©
    """
    print(f"üìä Nettoyage achats: {len(df)} enregistrements initiaux")
    
    # 1. Normaliser les types
    schema = {
        "id_achat": "int64",
        "id_client": "int64",
        "date_achat": "datetime64[ns]",
        "montant": "float64",
        "produit": "string"
    }
    df_clean = normalize_data_types(df, schema)
    
    # 2. Supprimer les doublons sur id_achat (cl√© primaire)
    df_clean = remove_duplicates(df_clean, subset=["id_achat"], keep="first")
    
    # 3. Standardiser les dates
    df_clean = standardize_dates(df_clean, date_columns=["date_achat"])
    
    # 4. Supprimer les valeurs nulles critiques
    df_clean = handle_missing_values(
        df_clean,
        strategy="drop",
        columns=["id_client", "date_achat", "montant"]
    )
    
    # 5. Supprimer les montants aberrants (n√©gatifs ou trop √©lev√©s)
    df_clean = df_clean[(df_clean["montant"] > 0) & (df_clean["montant"] <= 10000)]
    
    # 6. Int√©grit√© r√©f√©rentielle : v√©rifier que id_client existe dans clients
    if valid_client_ids is not None:
        initial_count = len(df_clean)
        df_clean = df_clean[df_clean["id_client"].isin(valid_client_ids)]
        removed_count = initial_count - len(df_clean)
        if removed_count > 0:
            print(f"‚ö†Ô∏è  {removed_count} achat(s) supprim√©(s) (id_client invalide)")
    
    # 7. Remplacer produit manquant par "UNKNOWN"
    df_clean = handle_missing_values(
        df_clean,
        strategy="fill",
        columns=["produit"],
        fill_value="UNKNOWN"
    )
    
    print(f"‚úÖ Nettoyage achats termin√©: {len(df_clean)} enregistrements valides")
    
    return df_clean


def clean_data_generic(df: pd.DataFrame, dataset_name: str = "dataset") -> pd.DataFrame:
    """
    Nettoie g√©n√©riquement n'importe quel DataFrame sans conna√Ætre le sch√©ma.
    Applique des transformations intelligentes bas√©es sur la d√©tection automatique.
    
    Args:
        df: DataFrame brut √† nettoyer
        dataset_name: Nom du dataset pour les logs
    
    Returns:
        DataFrame nettoy√©
    """
    if df is None or df.empty:
        print(f"‚ö†Ô∏è DataFrame vide pour {dataset_name}")
        return pd.DataFrame()
    
    print(f"üìä Nettoyage g√©n√©rique {dataset_name}: {len(df)} enregistrements initiaux, {len(df.columns)} colonnes")
    
    df_clean = df.copy()
    
    # 1. D√©tection automatique et normalisation des types
    for col in df_clean.columns:
        # D√©tecter les colonnes de dates (par nom ou contenu)
        if any(keyword in col.lower() for keyword in ['date', 'time', 'timestamp', 'created', 'updated']):
            try:
                df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', infer_datetime_format=True)
                # Supprimer les dates futures
                today = pd.Timestamp.now()
                df_clean = df_clean[df_clean[col] <= today]
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de convertir {col} en date: {e}")
        
        # D√©tecter les colonnes num√©riques
        elif df_clean[col].dtype == 'object':
            # Essayer de convertir en num√©rique si possible
            try:
                numeric_series = pd.to_numeric(df_clean[col], errors='coerce')
                if numeric_series.notna().sum() > len(df_clean) * 0.8:  # Si >80% sont num√©riques
                    df_clean[col] = numeric_series
            except:
                pass
        
        # D√©tecter les colonnes bool√©ennes
        elif df_clean[col].dtype == 'object':
            unique_vals = df_clean[col].dropna().unique()
            if len(unique_vals) <= 2:
                # Potentiellement bool√©en
                try:
                    df_clean[col] = df_clean[col].astype('string')
                except:
                    pass
    
    # 2. Supprimer les doublons complets
    initial_count = len(df_clean)
    df_clean = df_clean.drop_duplicates()
    removed_duplicates = initial_count - len(df_clean)
    if removed_duplicates > 0:
        print(f"‚ö†Ô∏è {removed_duplicates} doublon(s) complet(s) supprim√©(s)")
    
    # 3. Gestion intelligente des valeurs nulles
    for col in df_clean.columns:
        null_count = df_clean[col].isna().sum()
        null_pct = (null_count / len(df_clean)) * 100 if len(df_clean) > 0 else 0
        
        if null_pct > 50:
            # Si >50% de nulls, on supprime la colonne (probablement inutile)
            print(f"‚ö†Ô∏è Colonne {col} supprim√©e ({null_pct:.1f}% de valeurs nulles)")
            df_clean = df_clean.drop(columns=[col])
        elif null_pct > 0:
            # Sinon, on remplit intelligemment
            if df_clean[col].dtype in ['int64', 'float64']:
                df_clean[col].fillna(df_clean[col].median(), inplace=True)
            elif df_clean[col].dtype == 'datetime64[ns]':
                df_clean[col].fillna(pd.Timestamp.now(), inplace=True)
            else:
                df_clean[col].fillna("UNKNOWN", inplace=True)
    
    # 4. Supprimer les lignes avec trop de valeurs nulles (>80%)
    threshold = len(df_clean.columns) * 0.8
    initial_count = len(df_clean)
    df_clean = df_clean.dropna(thresh=threshold)
    removed_rows = initial_count - len(df_clean)
    if removed_rows > 0:
        print(f"‚ö†Ô∏è {removed_rows} ligne(s) supprim√©e(s) (trop de valeurs nulles)")
    
    # 5. Nettoyage des colonnes texte (trim, lowercase pour emails potentiels)
    for col in df_clean.columns:
        if df_clean[col].dtype == 'string' or df_clean[col].dtype == 'object':
            # D√©tecter les colonnes email
            if 'email' in col.lower() or 'mail' in col.lower():
                df_clean[col] = df_clean[col].str.lower().str.strip()
                # Filtrer les emails invalides
                df_clean = df_clean[df_clean[col].str.contains('@', na=False)]
            else:
                df_clean[col] = df_clean[col].astype(str).str.strip()
    
    # 6. D√©tection et nettoyage des valeurs aberrantes pour les colonnes num√©riques
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        if IQR > 0:
            lower_bound = Q1 - 3 * IQR  # Plus tol√©rant que 1.5
            upper_bound = Q3 + 3 * IQR
            outliers = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()
            if outliers > 0 and outliers < len(df_clean) * 0.1:  # Si <10% d'outliers
                df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
                print(f"‚ö†Ô∏è {outliers} valeur(s) aberrante(s) supprim√©e(s) dans {col}")
    
    print(f"‚úÖ Nettoyage g√©n√©rique {dataset_name} termin√©: {len(df_clean)} enregistrements valides")
    
    return df_clean

